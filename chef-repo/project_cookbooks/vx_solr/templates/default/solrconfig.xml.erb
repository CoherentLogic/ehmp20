<?xml version="1.0" encoding="UTF-8" ?>
<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the "License"); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

<!--
     For more details about configurations options that may appear in
     this file, see http://wiki.apache.org/solr/SolrConfigXml.
-->
<config>
    <lib dir="/opt/solr-5.1.0/server/solr-webapp/webapp/WEB-INF/lib" regex=".*\.jar" />

    <abortOnConfigurationError>${solr.abortOnConfigurationError:true}</abortOnConfigurationError>

    <!-- Controls what version of Lucene various components of Solr
       adhere to.  Generally, you want to use the latest version to
       get all bug fixes and improvements. It is highly recommended
       that you fully re-index after changing this setting as it can
       affect both how text is indexed and queried.
    -->
    <luceneMatchVersion>LUCENE_47</luceneMatchVersion>

    <!-- Data Directory

       Used to specify an alternate directory to hold all index data
       other than the default ./data under the Solr home.  If
       replication is in use, this should match the replication
       configuration.
    -->
    <dataDir>${solr.data.dir:}</dataDir>


    <!-- The DirectoryFactory to use for indexes.

       solr.StandardDirectoryFactory, the default, is filesystem
       based.  solr.RAMDirectoryFactory is memory based, not
       persistent, and doesn't work with replication.
    -->
    <directoryFactory name="DirectoryFactory"
                      class="${solr.directoryFactory:solr.StandardDirectoryFactory}"/>


    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   Index Config - These settings control low-level behavior of indexing
   Most example settings here show the default value, but are commented
   out, to more easily see where customizations have been made.

   Note: This replaces <indexDefaults> and <mainIndex> from older versions
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <indexConfig>
        <!-- maxFieldLength was removed in 4.0. To get similar behavior, include a
             LimitTokenCountFilterFactory in your fieldType definition. E.g.
         <filter class="solr.LimitTokenCountFilterFactory" maxTokenCount="10000"/>
        -->
        <!-- Maximum time to wait for a write lock (ms) for an IndexWriter. Default: 1000 -->
         <!--<writeLockTimeout>60000</writeLockTimeout>-->

        <!-- Expert: Enabling compound file will use less files for the index,
using fewer file descriptors on the expense of performance decrease.
Default in Lucene is "true". Default in Solr is "false" (since 3.6) -->
        <!-- <useCompoundFile>false</useCompoundFile> -->

        <!-- ramBufferSizeMB sets the amount of RAM that may be used by Lucene
indexing for buffering added documents and deletions before they are
flushed to the Directory.
maxBufferedDocs sets a limit on the number of documents buffered
before flushing.
If both ramBufferSizeMB and maxBufferedDocs is set, then
Lucene will flush based on whichever limit is hit first.  -->
        <!-- <ramBufferSizeMB>32</ramBufferSizeMB> -->
        <!-- <maxBufferedDocs>1000</maxBufferedDocs> -->

        <!-- Expert: Merge Policy
           The Merge Policy in Lucene controls how merging of segments is done.
           The default since Solr/Lucene 3.3 is TieredMergePolicy.
           The default since Lucene 2.3 was the LogByteSizeMergePolicy,
           Even older versions of Lucene used LogDocMergePolicy.
        -->
        <!--
          <mergePolicy class="org.apache.lucene.index.TieredMergePolicy">
            <int name="maxMergeAtOnce">10</int>
            <int name="segmentsPerTier">10</int>
          </mergePolicy>
        -->

        <!-- Merge Factor
           The merge factor controls how many segments will get merged at a time.
           For TieredMergePolicy, mergeFactor is a convenience parameter which
           will set both MaxMergeAtOnce and SegmentsPerTier at once.
           For LogByteSizeMergePolicy, mergeFactor decides how many new segments
           will be allowed before they are merged into one.
           Default is 10 for both merge policies.
        -->
        <!--General guidance is a value of 2 for query performance, 25 for indexing performance-->
      <mergeFactor>5</mergeFactor>

        <!-- Expert: Merge Scheduler
            The Merge Scheduler in Lucene controls how merges are
            performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
            can perform merges in the background using separate threads.
            The SerialMergeScheduler (Lucene 2.2 default) does not.
        -->
        <!--
        <mergeScheduler class="org.apache.lucene.index.ConcurrentMergeScheduler"/>
        -->

        <!-- LockFactory

     This option specifies which Lucene LockFactory implementation
     to use.

     single = SingleInstanceLockFactory - suggested for a
              read-only index or when there is no possibility of
              another process trying to modify the index.
     native = NativeFSLockFactory - uses OS native file locking.
              Do not use when multiple solr webapps in the same
              JVM are attempting to share a single index.
     simple = SimpleFSLockFactory  - uses a plain file for locking

     Defaults: 'native' is default for Solr3.6 and later, otherwise
               'simple' is the default

     More details on the nuances of each LockFactory...
     http://wiki.apache.org/lucene-java/AvailableLockFactories
-->
        <!--<lockType>simple</lockType>-->

        <!-- Unlock On Startup

             If true, unlock any held write or commit locks on startup.
             This defeats the locking mechanism that allows multiple
             processes to safely access a lucene index, and should be used
             with care. Default is "false".

             This is not needed if lock type is 'single'
         -->
        <!--<unlockOnStartup>true</unlockOnStartup>-->

        <!-- Expert: Controls how often Lucene loads terms into memory
           Default is 128 and is likely good for most everyone.
        -->
        <!-- <termIndexInterval>128</termIndexInterval> -->

        <!-- If true, IndexReaders will be reopened (often more efficient)
           instead of closed and then opened. Default: true
        -->
        <!--
      <reopenReaders>true</reopenReaders>
        -->

        <!-- Commit Deletion Policy

             Custom deletion policies can be specified here. The class must
             implement org.apache.lucene.index.IndexDeletionPolicy.

             http://lucene.apache.org/java/3_5_0/api/core/org/apache/lucene/index/IndexDeletionPolicy.html

             The default Solr IndexDeletionPolicy implementation supports
             deleting index commit points on number of commits, age of
             commit point and optimized status.

             The latest commit point should always be preserved regardless
             of the criteria.
        -->
        <!--
        <deletionPolicy class="solr.SolrDeletionPolicy">
        -->
        <!-- The number of commit points to be kept -->
        <!-- <str name="maxCommitsToKeep">1</str> -->
        <!-- The number of optimized commit points to be kept -->
        <!-- <str name="maxOptimizedCommitsToKeep">0</str> -->
        <!--
          Delete all commit points once they have reached the given age.
          Supports DateMathParser syntax e.g.
        -->
        <!--
           <str name="maxCommitAge">30MINUTES</str>
           <str name="maxCommitAge">1DAY</str>
        -->
        <!--
        </deletionPolicy>
        -->

        <!-- Lucene Infostream

           To aid in advanced debugging, Lucene provides an "InfoStream"
           of detailed information when indexing.

           Setting The value to true will instruct the underlying Lucene
           IndexWriter to write its debugging info the specified file
        -->
        <!-- <infoStream file="INFOSTREAM.txt">false</infoStream> -->
    </indexConfig>

    <!-- JMX

       This example enables JMX if and only if an existing MBeanServer
       is found, use this if you want to configure JMX through JVM
       parameters. Remove this to disable exposing Solr configuration
       and statistics to JMX.

       For more details see http://wiki.apache.org/solr/SolrJmx
    -->
    <jmx/>
    <!-- If you want to connect to a particular server, specify the
       agentId
    -->
    <!-- <jmx agentId="myAgent" /> -->
    <!-- If you want to start a new MBeanServer, specify the serviceUrl -->
    <!-- <jmx serviceUrl="service:jmx:rmi:///jndi/rmi://localhost:9999/solr"/>
    -->

    <!-- The default high-performance update handler -->
    <updateHandler class="solr.DirectUpdateHandler2">

        <!-- Enables a transaction log, used for real-time get, durability, and
             and solr cloud replica recovery.  The log can grow as big as
             uncommitted changes to the index, so use of a hard autoCommit
             is recommended (see below).
             "dir" - the target directory for transaction logs, defaults to the
                    solr data directory.  -->
        <updateLog>
            <str name="dir">${solr.ulog.dir:}</str>
        </updateLog>

        <!-- AutoCommit

             Perform a hard commit automatically under certain conditions.
             Instead of enabling autoCommit, consider using "commitWithin"
             when adding documents.

             http://wiki.apache.org/solr/UpdateXmlMessages

             maxDocs - Maximum number of documents to add since the last
                       commit before automatically triggering a new commit.

             maxTime - Maximum amount of time in ms that is allowed to pass
                       since a document was added before automatically
                       triggering a new commit.
             openSearcher - if false, the commit causes recent index changes
               to be flushed to stable storage, but does not cause a new
               searcher to be opened to make those changes visible.

             If the updateLog is enabled, then it's highly recommended to
             have some sort of hard autoCommit to limit the log size.
          -->

        <!--autoCommit will force changes to be flushed to stable storage.  However, openSearcher is false, so changes
        will not immediately be seen.  The autoSoftCommit will make changes visible.  The frequency is set so
        autoSoftcommit is not a multiple of autoCommit, reducing the frequency of both events firing at same time.-->
        <autoCommit>
            <maxTime>2000</maxTime>
            <openSearcher>true</openSearcher>
        </autoCommit>

        <!-- softAutoCommit is like autoCommit except it causes a
             'soft' commit which only ensures that changes are visible
             but does not ensure that data is synced to disk.  This is
             faster and more near-realtime friendly than a hard commit.
          -->
        <!--<autoSoftCommit>-->
            <!--<maxTime>65000</maxTime>-->
        <!--</autoSoftCommit>-->

        <!-- Update Related Event Listeners

             Various IndexWriter related events can trigger Listeners to
             take actions.

             postCommit - fired after every commit or optimize command
             postOptimize - fired after every optimize command
          -->
        <!-- The RunExecutableListener executes an external command from a
             hook such as postCommit or postOptimize.

             exe - the name of the executable to run
             dir - dir to use as the current working directory. (default=".")
             wait - the calling thread waits until the executable returns.
                    (default="true")
             args - the arguments to pass to the program.  (default is none)
             env - environment variables to set.  (default is none)
          -->
        <!-- This example shows how RunExecutableListener could be used
             with the script based replication...
             http://wiki.apache.org/solr/CollectionDistribution
          -->
        <!--
           <listener event="postCommit" class="solr.RunExecutableListener">
             <str name="exe">solr/bin/snapshooter</str>
             <str name="dir">.</str>
             <bool name="wait">true</bool>
             <arr name="args"> <str>arg1</str> <str>arg2</str> </arr>
             <arr name="env"> <str>MYVAR=val1</str> </arr>
           </listener>
          -->

    </updateHandler>


    <!-- IndexReaderFactory

       Use the following format to specify a custom IndexReaderFactory,
       which allows for alternate IndexReader implementations.

       ** Experimental Feature **

       Please note - Using a custom IndexReaderFactory may prevent
       certain other features from working. The API to
       IndexReaderFactory may change without warning or may even be
       removed from future releases if the problems cannot be
       resolved.


       ** Features that may not work with custom IndexReaderFactory **

       The ReplicationHandler assumes a disk-resident index. Using a
       custom IndexReader implementation may cause incompatibility
       with ReplicationHandler and may cause replication to not work
       correctly. See SOLR-1366 for details.

    -->
    <!--
    <indexReaderFactory name="IndexReaderFactory" class="package.class">
      <str name="someArg">Some Value</str>
    </indexReaderFactory >
    -->
    <!-- By explicitly declaring the Factory, the termIndexDivisor can
       be specified.
    -->
    <!--
     <indexReaderFactory name="IndexReaderFactory"
                         class="solr.StandardIndexReaderFactory">
       <int name="setTermIndexDivisor">12</int>
     </indexReaderFactory >
    -->


    <query>
        <!-- Max Boolean Clauses

           Maximum number of clauses in each BooleanQuery,  an exception
           is thrown if exceeded.

           ** WARNING **

           This option actually modifies a global Lucene property that
           will affect all SolrCores.  If multiple solrconfig.xml files
           disagree on this property, the value at any given moment will
           be based on the last SolrCore to be initialized.

        -->
        <maxBooleanClauses>2048</maxBooleanClauses>


        <!-- Solr Internal Query Caches

             There are two implementations of cache available for Solr,
             LRUCache, based on a synchronized LinkedHashMap, and
             FastLRUCache, based on a ConcurrentHashMap.

             FastLRUCache has faster gets and slower puts in single
             threaded operation and thus is generally faster than LRUCache
             when the hit ratio of the cache is high (> 75%), and may be
             faster under other scenarios on multi-cpu systems.
        -->

        <!-- Filter Cache

           Cache used by SolrIndexSearcher for filters (DocSets),
           unordered sets of *all* documents that match a query.  When a
           new searcher is opened, its caches may be prepopulated or
           "autowarmed" using data from caches in the old searcher.
           autowarmCount is the number of items to prepopulate.  For
           LRUCache, the autowarmed items will be the most recently
           accessed items.

           Parameters:
             class - the SolrCache implementation LRUCache or
                 (LRUCache or FastLRUCache)
             size - the maximum number of entries in the cache
             initialSize - the initial capacity (number of entries) of
                 the cache.  (see java.util.HashMap)
             autowarmCount - the number of entries to prepopulate from
                 and old cache.
        -->
        <filterCache class="solr.FastLRUCache"
                     size="<%= @filtercache_size %>"
                     initialSize="<%= @filtercache_initialsize %>"
                     autowarmCount="<%= @filtercache_autowarmcount %>"/>

        <!-- Query Result Cache

           Caches results of searches - ordered lists of document ids
           (DocList) based on a query, a sort, and the range of documents requested.
        -->
        <queryResultCache class="solr.LRUCache"
                          size="512"
                          initialSize="512"
                          autowarmCount="0"/>

        <!-- Document Cache

           Caches Lucene Document objects (the stored fields for each
           document).  Since Lucene internal document ids are transient,
           this cache will not be autowarmed.
        -->
        <documentCache class="solr.LRUCache"
                       size="512"
                       initialSize="512"
                       autowarmCount="0"/>

        <!-- Field Value Cache

           Cache used to hold field values that are quickly accessible
           by document id.  The fieldValueCache is created by default
           even if not configured here.
        -->
        <!--
         <fieldValueCache class="solr.FastLRUCache"
                          size="512"
                          autowarmCount="128"
                          showItems="32" />
        -->

        <!-- Custom Cache

           Example of a generic cache.  These caches may be accessed by
           name through SolrIndexSearcher.getCache(),cacheLookup(), and
           cacheInsert().  The purpose is to enable easy caching of
           user/application level data.  The regenerator argument should
           be specified as an implementation of solr.CacheRegenerator
           if autowarming is desired.
        -->
        <!--
         <cache name="myUserCache"
                class="solr.LRUCache"
                size="4096"
                initialSize="1024"
                autowarmCount="1024"
                regenerator="com.mycompany.MyRegenerator"
                />
        -->


        <!-- Lazy Field Loading

             If true, stored fields that are not requested will be loaded
             lazily.  This can result in a significant speed improvement
             if the usual case is to not load all stored fields,
             especially if the skipped fields are large compressed text
             fields.
        -->
        <enableLazyFieldLoading>true</enableLazyFieldLoading>

        <!-- Use Filter For Sorted Query

           A possible optimization that attempts to use a filter to
           satisfy a search.  If the requested sort does not include
           score, then the filterCache will be checked for a filter
           matching the query. If found, the filter will be used as the
           source of document ids, and then the sort will be applied to
           that.

           For most situations, this will not be useful unless you
           frequently get the same search repeatedly with different sort
           options, and none of them ever use "score"
        -->
        <!--
         <useFilterForSortedQuery>true</useFilterForSortedQuery>
        -->

        <!-- Result Window Size

           An optimization for use with the queryResultCache.  When a search
           is requested, a superset of the requested number of document ids
           are collected.  For example, if a search for a particular query
           requests matching documents 10 through 19, and queryWindowSize is 50,
           then documents 0 through 49 will be collected and cached.  Any further
           requests in that range can be satisfied via the cache.
        -->
        <queryResultWindowSize>20</queryResultWindowSize>

        <!-- Maximum number of documents to cache for any entry in the
           queryResultCache.
        -->
        <queryResultMaxDocsCached>200</queryResultMaxDocsCached>

        <!-- Query Related Event Listeners

           Various IndexSearcher related events can trigger Listeners to
           take actions.

           newSearcher - fired whenever a new searcher is being prepared
           and there is a current searcher handling requests (aka
           registered).  It can be used to prime certain caches to
           prevent long request times for certain requests.

           firstSearcher - fired whenever a new searcher is being
           prepared but there is no current registered searcher to handle
           requests or to gain autowarming data from.


        -->
        <!-- QuerySenderListener takes an array of NamedList and executes a
           local query request for each NamedList in sequence.
        -->
        <listener event="newSearcher" class="solr.QuerySenderListener">
            <arr name="queries">
                <!--
                 <lst><str name="q">solr</str><str name="sort">price asc</str></lst>
                 <lst><str name="q">rocks</str><str name="sort">weight asc</str></lst>
                -->
            </arr>
        </listener>
        <listener event="firstSearcher" class="solr.QuerySenderListener">
            <arr name="queries">
                <lst>
                    <str name="q">static firstSearcher warming in solrconfig.xml</str>
                    <!--may want to add spellcheck.build here -->
                    <!-- <str name="spellcheck.build">true</str> -->
                </lst>
            </arr>
        </listener>

        <!-- Use Cold Searcher

           If a search request comes in and there is no current
           registered searcher, then immediately register the still
           warming searcher and use it.  If "false" then all requests
           will block until the first searcher is done warming.
        -->
        <useColdSearcher>false</useColdSearcher>

        <!-- Max Warming Searchers

           Maximum number of searchers that may be warming in the
           background concurrently.  An error is returned if this limit
           is exceeded.

           Recommend values of 1-2 for read-only slaves, higher for
           masters w/o cache warming.
        -->
        <maxWarmingSearchers>2</maxWarmingSearchers>

    </query>


    <!-- Request Dispatcher

       This section contains instructions for how the SolrDispatchFilter
       should behave when processing requests for this SolrCore.

       handleSelect affects the behavior of requests such as /select?qt=XXX

       handleSelect="true" will cause the SolrDispatchFilter to process
       the request and will result in consistent error handling and
       formatting for all types of requests.

       handleSelect="false" will cause the SolrDispatchFilter to
       ignore "/select" requests and fallback to using the legacy
       SolrServlet and it's Solr 1.1 style error formatting
    -->
    <requestDispatcher handleSelect="true">
        <!-- Request Parsing

           These settings indicate how Solr Requests may be parsed, and
           what restrictions may be placed on the ContentStreams from
           those requests

           enableRemoteStreaming - enables use of the stream.file
           and stream.url parameters for specifying remote streams.

           multipartUploadLimitInKB - specifies the max size of
           Multipart File Uploads that Solr will allow in a Request.

           *** WARNING ***
           The settings below authorize Solr to fetch remote files, You
           should make sure your system has some authentication before
           using enableRemoteStreaming="true"

        -->
        <requestParsers enableRemoteStreaming="true"
                        multipartUploadLimitInKB="2048000"/>

        <!-- HTTP Caching

           Set HTTP caching related parameters (for proxy caches and clients).

           The options below instruct Solr not to output any HTTP Caching
           related headers
        -->
        <httpCaching never304="true"/>
        <!-- If you include a <cacheControl> directive, it will be used to
           generate a Cache-Control header (as well as an Expires header
           if the value contains "max-age=")

           By default, no Cache-Control header is generated.

           You can use the <cacheControl> option even if you have set
           never304="true"
        -->
        <!--
         <httpCaching never304="true" >
           <cacheControl>max-age=30, public</cacheControl>
         </httpCaching>
        -->
        <!-- To enable Solr to respond with automatically generated HTTP
           Caching headers, and to response to Cache Validation requests
           correctly, set the value of never304="false"

           This will cause Solr to generate Last-Modified and ETag
           headers based on the properties of the Index.

           The following options can also be specified to affect the
           values of these headers...

           lastModFrom - the default value is "openTime" which means the
           Last-Modified value (and validation against If-Modified-Since
           requests) will all be relative to when the current Searcher
           was opened.  You can change it to lastModFrom="dirLastMod" if
           you want the value to exactly correspond to when the physical
           index was last modified.

           etagSeed="..." is an option you can change to force the ETag
           header (and validation against If-None-Match requests) to be
           different even if the index has not changed (ie: when making
           significant changes to your config file)

           (lastModifiedFrom and etagSeed are both ignored if you use
           the never304="true" option)
        -->
        <!--
         <httpCaching lastModifiedFrom="openTime"
                      etagSeed="Solr">
           <cacheControl>max-age=30, public</cacheControl>
         </httpCaching>
        -->
    </requestDispatcher>

    <!-- Request Handlers

       http://wiki.apache.org/solr/SolrRequestHandler

       incoming queries will be dispatched to the correct handler
       based on the path or the qt (query type) param.

       Names starting with a '/' are accessed with the a path equal to
       the registered name.  Names without a leading '/' are accessed
       with: http://host/app/[core/]select?qt=name

       If a /select request is processed with out a qt param
       specified, the requestHandler that declares default="true" will
       be used.

       If a Request Handler is declared with startup="lazy", then it will
       not be initialized until the first request that uses it.

    -->
    <!-- SearchHandler

       http://wiki.apache.org/solr/SearchHandler

       For processing Search Queries, the primary Request Handler
       provided with Solr is "SearchHandler" It delegates to a sequent
       of SearchComponents (see below) and supports distributed
       queries across multiple shards
    -->
    <requestHandler name="search" class="solr.SearchHandler" default="true">
        <!-- default values for query parameters can be specified, these
           will be overridden by parameters in the request
        -->
        <lst name="defaults">
            <str name="echoParams">explicit</str>
            <int name="rows">10</int>
        </lst>
        <arr name="last-components">
        <!--TODO: Do we utilize spell suggestions in the query, or only via the /suggest?  If not, should remove-->
          <str>suggest_spell_file</str>
        </arr>
    </requestHandler>

    <!-- realtime get handler, guaranteed to return the latest stored fields of
     any document, without the need to commit or open a new searcher.  The
     current implementation relies on the updateLog feature being enabled. -->
    <requestHandler name="/get" class="solr.RealTimeGetHandler">
        <lst name="defaults">
            <str name="omitHeader">true</str>
            <str name="wt">json</str>
            <str name="indent">true</str>
        </lst>
    </requestHandler>

    <!-- Update Request Handler.

       http://wiki.apache.org/solr/UpdateXmlMessages

       The canonical Request Handler for Modifying the Index through
       commands specified using XML, JSON, CSV, or JAVABIN

       Note: Since solr1.1 requestHandlers requires a valid content
       type header if posted in the body. For example, curl now
       requires: -H 'Content-type:text/xml; charset=utf-8'

       To override the request content type and force a specific
       Content-type, use the request parameter:
         ?update.contentType=text/csv

       This handler will pick a response format to match the input
       if the 'wt' parameter is not explicit
    -->
    <requestHandler name="/update" class="solr.UpdateRequestHandler">
    </requestHandler>

    <!-- Admin Handlers

         Admin Handlers - This will register all the standard admin
         RequestHandlers.
      -->
    <!--<requestHandler name="/admin/" class="solr.admin.AdminHandlers" />-->
    <requestHandler name="/analysis/field"
                    startup="lazy"
                    class="solr.FieldAnalysisRequestHandler" />
    <requestHandler name="/analysis/document"
                    class="solr.DocumentAnalysisRequestHandler"
                    startup="lazy" />

    <!-- ping/healthcheck -->
    <requestHandler name="/admin/ping" class="solr.PingRequestHandler">
        <lst name="invariants">
            <str name="q">solrpingquery</str>
        </lst>
        <lst name="defaults">
            <str name="echoParams">all</str>
        </lst>
        <!-- An optional feature of the PingRequestHandler is to configure the
             handler with a "healthcheckFile" which can be used to enable/disable
             the PingRequestHandler.
             relative paths are resolved against the data dir
          -->
        <!-- <str name="healthcheckFile">server-enabled.txt</str> -->
    </requestHandler>

    <!-- Echo the request contents back to the client -->
    <requestHandler name="/debug/dump" class="solr.DumpRequestHandler" >
        <lst name="defaults">
            <str name="echoParams">explicit</str>
            <str name="echoHandler">true</str>
        </lst>
    </requestHandler>

    <searchComponent class="solr.SpellCheckComponent" name="suggest_spell_file">
<!--TODO Why is buildOnCommit true for all of these, expensive op  https://wiki.apache.org/solr/SpellCheckComponent -->
<!--Maybe not as expensive on the FSTLookup which is designed for this use-case (fast prefix based tree)-->
<!--But should be able to turn off for the file based checker which should never update-->

<!--Note that the filebasedSpellChecker Index has to be built, this is forced by-->
<!--adding to a query (to the select or suggest endpoints) &spellcheck.build=true-->
<!--This is expensive, taking 15 seconds on local box, so need to ensure it doesn't get used more than once after install/update-->

        <lst name="spellchecker">
            <str name="name">file</str>
            <str name="field">spell</str>   <!-- TODO: misconfiguration, doesn't do anything -->
            <str name="classname">solr.FileBasedSpellChecker</str>
            <str name="sourceLocation">solr-spell.txt</str>
            <str name="characterEncoding">UTF-8</str>
            <str name="spellcheckIndexDir">./spellcheckerFileSolrSpell</str>
            <str name="buildOnCommit">false</str>
            <str name="buildOnOptimize">true</str>
        </lst>
        <lst name="spellchecker">
            <str name="name">suggest</str>
            <str name="classname">org.apache.solr.spelling.suggest.Suggester</str>
            <str name="lookupImpl">org.apache.solr.spelling.suggest.fst.FSTLookup</str>
            <!-- Alternatives to lookupImpl:
                 org.apache.solr.spelling.suggest.fst.FSTLookup   [finite state automaton]
                 org.apache.solr.spelling.suggest.fst.WFSTLookupFactory [weighted finite state automaton]
                 org.apache.solr.spelling.suggest.jaspell.JaspellLookup [default, jaspell-based]
                 org.apache.solr.spelling.suggest.tst.TSTLookup   [ternary trees]
            -->
            <str name="field">phrase</str>  <!-- the indexed field to derive suggestions from -->
            <float name="threshold">0.</float>
            <str name="buildOnCommit">false</str>
            <str name="buildOnOptimize">true</str>
            <str name="storeDir">./spellcheckerSuggesterFSTLookup</str>
        </lst>
        <!--TODO: It does not look like this is used anywhere, it is commented out of the suggest handler-->
        <!--<lst name="spellchecker">-->
            <!--<str name="name">spell</str>-->
            <!--<str name="field">spell</str>-->
            <!--<str name="classname">solr.DirectSolrSpellChecker</str>-->
            <!--<str name="combineWords">true</str>-->
            <!--<str name="breakWords">true</str>-->
            <!--<int name="maxChanges">10</int>-->
            <!--<str name="distanceMeasure">internal</str>-->
            <!--<float name="accuracy">0.5</float>-->
            <!--<str name="buildOnCommit">true</str>-->
            <!--<str name="buildOnOptimize">true</str>-->
        <!--</lst>-->
    </searchComponent>

    <searchComponent class="solr.SuggestComponent" name="suggester" startup="lazy">
      <lst name="suggester">
        <str name="name">phrase_suggester</str>
        <str name="lookupImpl">AnalyzingInfixLookupFactory</str>
        <str name="dictionaryImpl">HighFrequencyDictionaryFactory</str>
        <str name="field">phrase</str>
        <!--  <str name="weightField">kind</str> -->
        <str name="payloadField">pid</str>
        <!--<str name="indexPath">${solr.solr.home:}/suggest_infix</str>-->
        <!--<str name="storeDir">${solr.solr.home:}/suggest_infix_dict</str>-->
        <str name="suggestAnalyzerFieldType">text_general</str>
        <str name="buildOnCommit">false</str>
        <str name="buildOnOptimize">true</str>
      </lst>
      <lst name="suggester">
        <str name="name">freetext_suggester</str>
        <str name="lookupImpl">FreeTextLookupFactory</str>
        <str name="dictionaryImpl">HighFrequencyDictionaryFactory</str>
        <str name="field">spell</str>
        <str name="payloadField">pid</str>
        <str name="suggestFreeTextAnalyzerFieldType">text_general</str>
        <str name="buildOnCommit">false</str>
        <str name="buildOnOptimize">true</str>
      </lst>
    </searchComponent>

    <!-- a handler for the suggest component -->
    <requestHandler class="solr.SearchHandler" name="/suggest">

        <lst name="defaults">
          <str name="indent">false</str>
          <str name="suggest">true</str>
          <str name="suggest.dictionary">phrase_suggester</str>
          <str name="suggest.dictionary">freetext_suggester</str>
          <str name="spellcheck">true</str>
          <str name="spellcheck.dictionary">file</str>
          <str name="spellcheck.dictionary">suggest</str>
          <!--<str name="spellcheck.dictionary">spell</str> -->
          <str name="spellcheck.onlyMorePopular">false</str>
          <str name="spellcheck.count">5</str>
          <str name="spellcheck.collate">true</str>
          <str name="spellcheck.extendedResults">true</str>
          <str name="shards.qt">/suggest</str>
        </lst>
        <arr name="components">
            <str>suggester</str>
            <str>suggest_spell_file</str>
        </arr>
    </requestHandler>


    <!-- Terms Component

       http://wiki.apache.org/solr/TermsComponent

       A component to return terms and document frequency of those
       terms
    -->
    <searchComponent name="terms" class="solr.TermsComponent"/>

    <!-- A request handler for demonstrating the terms component -->
    <requestHandler name="/terms" class="solr.SearchHandler" startup="lazy">
        <lst name="defaults">
            <bool name="terms">true</bool>
        </lst>
        <arr name="components">
            <str>terms</str>
        </arr>
    </requestHandler>


    <!-- Highlighting Component

       http://wiki.apache.org/solr/HighlightingParameters
    -->
    <searchComponent class="solr.HighlightComponent" name="highlight">
        <highlighting>
            <!-- Configure the standard fragmenter -->
            <!-- This could most likely be commented out in the "default" case -->
            <fragmenter name="gap"
                        default="true"
                        class="solr.highlight.GapFragmenter">
                <lst name="defaults">
                    <int name="hl.fragsize">100</int>
                </lst>
            </fragmenter>

            <!-- A regular-expression-based fragmenter
               (for sentence extraction)
            -->
            <fragmenter name="regex"
                        class="solr.highlight.RegexFragmenter">
                <lst name="defaults">
                    <!-- slightly smaller fragsizes work better because of slop -->
                    <int name="hl.fragsize">70</int>
                    <!-- allow 50% slop on fragment sizes -->
                    <float name="hl.regex.slop">0.5</float>
                    <!-- a basic sentence pattern -->
                    <str name="hl.regex.pattern">[-\w ,/\n\&quot;&apos;]{20,200}</str>
                </lst>
            </fragmenter>

            <!-- Configure the standard formatter -->
            <formatter name="html"
                       default="true"
                       class="solr.highlight.HtmlFormatter">
                <lst name="defaults">
                    <str name="hl.simple.pre"><![CDATA[<span class="cpe-search-term-match">]]></str>
                    <str name="hl.simple.post"><![CDATA[</span>]]></str>
                </lst>
            </formatter>

            <!-- Configure the standard encoder -->
            <encoder name="html"
                     class="solr.highlight.HtmlEncoder"/>

            <!-- Configure the standard fragListBuilder -->
            <fragListBuilder name="simple"
                             default="true"
                             class="solr.highlight.SimpleFragListBuilder"/>

            <!-- Configure the single fragListBuilder -->
            <fragListBuilder name="single"
                             class="solr.highlight.SingleFragListBuilder"/>

            <!-- default tag FragmentsBuilder -->
            <fragmentsBuilder name="default"
                              default="true"
                              class="solr.highlight.ScoreOrderFragmentsBuilder">
                <!--
                <lst name="defaults">
                  <str name="hl.multiValuedSeparatorChar">/</str>
                </lst>
                -->
            </fragmentsBuilder>

            <!-- multi-colored tag FragmentsBuilder -->
            <fragmentsBuilder name="colored"
                              class="solr.highlight.ScoreOrderFragmentsBuilder">
                <lst name="defaults">
                    <str name="hl.tag.pre"><![CDATA[
               <b style="background:yellow">,<b style="background:lawgreen">,
               <b style="background:aquamarine">,<b style="background:magenta">,
               <b style="background:palegreen">,<b style="background:coral">,
               <b style="background:wheat">,<b style="background:khaki">,
               <b style="background:lime">,<b style="background:deepskyblue">]]></str>
                    <str name="hl.tag.post"><![CDATA[</b>]]></str>
                </lst>
            </fragmentsBuilder>
        </highlighting>
    </searchComponent>

    <!-- XSLT response writer transforms the XML output by any xslt file found
       in Solr's conf/xslt directory.  Changes to xslt files are checked for
       every xsltCacheLifetimeSeconds.
    -->
    <queryResponseWriter name="xslt" class="solr.XSLTResponseWriter">
        <int name="xsltCacheLifetimeSeconds">5</int>
    </queryResponseWriter>

  <!-- Main configuration for a synonym-expanding ExtendedDismaxQParserPlugin.  See
       https://github.com/healthonnet/hon-lucene-synonyms
       for more info on this plugin.
    -->
  <queryParser name="synonym_edismax" class="solr.SynonymExpandingExtendedDismaxQParserPlugin">
    <!-- You can define more than one synonym analyzer in the following list.
         For example, you might have one set of synonyms for English, one for French,
         one for Spanish, etc.
      -->
    <lst name="synonymAnalyzers">
      <!-- Name your analyzer something useful, e.g. "analyzer_en", "analyzer_fr", "analyzer_es", etc.
           If you only have one, the name doesn't matter (hence "myCoolAnalyzer").
        -->
      <lst name="myCoolAnalyzer">
        <!-- We recommend a PatternTokenizerFactory that tokenizes based on whitespace and quotes.
             This seems to work best with most people's synonym files.
             For details, read the discussion here: http://github.com/healthonnet/hon-lucene-synonyms/issues/26
          -->
        <lst name="tokenizer">
          <str name="class">solr.PatternTokenizerFactory</str>
          <str name="pattern"><![CDATA[(?:\s|\")+]]></str>
        </lst>
        <!-- The ShingleFilterFactory outputs synonyms of multiple token lengths (e.g. unigrams, bigrams, trigrams, etc.).
             The default here is to assume you don't have any synonyms longer than 4 tokens.
             You can tweak this depending on what your synonyms look like. E.g. if you only have unigrams, you can remove
             it entirely, and if your synonyms are up to 7 tokens in length, you should set the maxShingleSize to 7.
          -->
        <lst name="filter">
          <str name="class">solr.ShingleFilterFactory</str>
          <str name="outputUnigramsIfNoShingles">true</str>
          <str name="outputUnigrams">true</str>
          <str name="minShingleSize">2</str>
          <str name="maxShingleSize">4</str>
        </lst>
        <!-- This is where you set your synonym file.  For the unit tests and "Getting Started" examples, we use example_synonym_file.txt.
             This plugin will work best if you keep expand set to true and have all your synonyms comma-separated (rather than =>-separated).
          -->
        <lst name="filter">
          <str name="class">solr.SynonymFilterFactory</str>
          <str name="tokenizerFactory">solr.KeywordTokenizerFactory</str>
          <str name="synonyms">synonyms.txt,synonyms-ClinicalSenseInventoryII.txt,specialistNLP.txt</str>
          <str name="expand">true</str>
          <str name="ignoreCase">true</str>
        </lst>
      </lst>
    </lst>
  </queryParser>

</config>
